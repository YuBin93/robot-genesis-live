# api/analyze.py

from http.server import BaseHTTPRequestHandler
import json
import os
from urllib.parse import urlparse, parse_qs
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from duckduckgo_search import DDGS
import re # ÂºïÂÖ•Ê≠£ÂàôË°®ËææÂºèÂ∫ì

# --- 1. ÈÖçÁΩÆ‰∏éÂàùÂßãÂåñ ---
API_KEY = os.getenv("GEMINI_API_KEY")
if API_KEY:
    genai.configure(api_key=API_KEY)
else:
    print("CRITICAL WARNING: GEMINI_API_KEY environment variable not found.")

# --- 2. PromptÊûÑÂª∫ÂáΩÊï∞ ---
def build_prompt(page_content, robot_name):
    desired_json_structure = """
    {
      "name": "Robot's full name", "manufacturer": "The company that created the robot", "type": "Type of robot (e.g., Quadruped, Humanoid)",
      "specs": { "Weight": "Weight of the robot (e.g., 75 kg)", "Payload": "Payload capacity (e.g., 25 kg)", "Speed": "Maximum speed (e.g., 1.5 m/s)" },
      "modules": { "Perception": { "components": ["List of sensors like Cameras, LiDAR, IMU"], "suppliers": ["List of potential suppliers"] }, "Locomotion": { "components": ["List of components like Actuators, Hydraulic systems"], "suppliers": ["List of potential suppliers"] } }
    }
    """
    prompt = f"""
    Analyze the text from a webpage about the robot named '{robot_name}'. Your task is to extract key information and provide the output ONLY in a valid JSON format. The JSON object must strictly adhere to the structure shown below. If a piece of information is not available in the text, use "N/A" as the value. Do not include any introductory text, closing remarks, or markdown formatting like ```json.

    ### Desired JSON Structure:
    {desired_json_structure}
    ### Page Content to Analyze:
    ---
    {page_content[:20000]} 
    ---
    ### Extracted JSON Data:
    """
    return prompt

# --- 3. Êñ∞Â¢û‰∏Ä‰∏™ËæÖÂä©ÂáΩÊï∞ÔºöÊô∫ËÉΩÊèêÂèñJSON ---
def extract_json_from_text(text):
    """
    ‰ΩøÁî®Â§öÁßçÊñπÊ≥ï‰ªéÂèØËÉΩÂåÖÂê´È¢ùÂ§ñÊñáÊú¨ÁöÑÂ≠óÁ¨¶‰∏≤‰∏≠ÊèêÂèñJSONÂØπË±°„ÄÇ
    """
    # ÊñπÊ≥ï1ÔºöÂØªÊâæË¢´Markdown‰ª£Á†ÅÂùóÂåÖË£πÁöÑJSON
    # Ëøô‰ºöÂØªÊâæ ```json ... ``` ËøôÊ†∑ÁöÑÁªìÊûÑ
    match = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1))
        except json.JSONDecodeError:
            pass # Â¶ÇÊûúÂ§±Ë¥•ÔºåÂ∞±ÁªßÁª≠Â∞ùËØï‰∏ã‰∏ÄÁßçÊñπÊ≥ï

    # ÊñπÊ≥ï2ÔºöÂØªÊâæÁ¨¨‰∏Ä‰∏™ '{' ÂíåÊúÄÂêé‰∏Ä‰∏™ '}'
    try:
        start_index = text.find('{')
        end_index = text.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            potential_json = text[start_index : end_index + 1]
            return json.loads(potential_json)
    except json.JSONDecodeError:
        pass

    # Â¶ÇÊûúÊâÄÊúâÊñπÊ≥ïÈÉΩÂ§±Ë¥•‰∫ÜÔºåÂ∞±ÊäõÂá∫ÂºÇÂ∏∏
    raise json.JSONDecodeError("Could not find a valid JSON object in the model's response.", text, 0)

# --- 4. Serverless Function ‰∏ªÂ§ÑÁêÜÈÄªËæë ---
class handler(BaseHTTPRequestHandler):
    def do_GET(self):
        if not API_KEY:
            self.send_response(500); self.send_header('Content-type', 'application/json'); self.end_headers()
            self.wfile.write(json.dumps({"error": "Server configuration error: The Gemini API Key is not set."}).encode())
            return

        query_components = parse_qs(urlparse(self.path).query)
        robot_name = query_components.get('robot', [None])[0]

        if not robot_name:
            self.send_response(400); self.send_header('Content-type', 'application/json'); self.end_headers()
            self.wfile.write(json.dumps({"error": "Please provide a robot name."}).encode())
            return
        
        response_text_for_logging = ""
        try:
            print(f"üïµÔ∏è Searching for '{robot_name}'...")
            with DDGS() as ddgs:
                results = [r for r in ddgs.text(f"{robot_name} robot wikipedia", max_results=3)]

            if not results: raise ValueError(f"Could not find any search results for '{robot_name}'.")

            target_url = next((r['href'] for r in results if 'wikipedia.org' in r['href']), results[0]['href'])
            print(f"üéØ Best URL found: {target_url}")

            page_response = requests.get(target_url, headers={'User-Agent': 'Robot-Genesis-Live-Analyzer/1.3'}, timeout=10)
            page_response.raise_for_status()
            soup = BeautifulSoup(page_response.content, 'html.parser')
            page_text = (soup.find(id='mw-content-text') or soup.find('body')).get_text(separator=' ', strip=True)

            print(f"‚ú® Analyzing with Gemini...")
            prompt = build_prompt(page_text, robot_name)
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            safety_settings = [ {"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"] ]
            
            gemini_response = model.generate_content(prompt, safety_settings=safety_settings)
            
            response_text_for_logging = gemini_response.text
            
            robot_data = extract_json_from_text(response_text_for_logging)
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(robot_data).encode())

        except json.JSONDecodeError:
            print(f"‚ùå JSONDecodeError: Could not extract valid JSON. Model's raw response was: '{response_text_for_logging}'")
            self.send_response(500); self.send_header('Content-type', 'application/json'); self.end_headers()
            self.wfile.write(json.dumps({"error": "The AI model's response was not in the expected format. Please try again."}).encode())
        except Exception as e:
            print(f"‚ùå An unhandled error occurred: {e}")
            self.send_response(500); self.send_header('Content-type', 'application/json'); self.end_headers()
            self.wfile.write(json.dumps({"error": f"An internal error occurred: {str(e)}"}).encode())
