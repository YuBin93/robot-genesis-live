# api/analyze.py

from http.server import BaseHTTPRequestHandler
import json
import os
from urllib.parse import urlparse, parse_qs
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from duckduckgo_search import DDGS

# --- 1. é…ç½®ä¸åˆå§‹åŒ– ---
# ä»Vercelçš„ç¯å¢ƒå˜é‡ä¸­å®‰å…¨åœ°è·å–API Key
API_KEY = os.getenv("GEMINI_API_KEY")

# åªæœ‰åœ¨API_KEYå­˜åœ¨æ—¶æ‰é…ç½®SDKï¼Œé¿å…åœ¨æœ¬åœ°æµ‹è¯•æ—¶å› ç¼ºå°‘KEYè€Œå´©æºƒ
if API_KEY:
    genai.configure(api_key=API_KEY)
else:
    # åœ¨éƒ¨ç½²ç¯å¢ƒï¼ˆVercelï¼‰ä¸­ï¼Œå¦‚æœæ‰¾ä¸åˆ°KEYï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¥é‡é”™è¯¯
    # åœ¨æ—¥å¿—ä¸­æ‰“å°è­¦å‘Šï¼Œä»¥ä¾¿äºè°ƒè¯•
    print("CRITICAL WARNING: GEMINI_API_KEY environment variable not found.")

# --- 2. Promptæ„å»ºå‡½æ•° ---
# è¿™ä¸ªå‡½æ•°è´Ÿè´£æ„å»ºç»™AIçš„æŒ‡ä»¤ï¼Œä¿æŒä¸å˜
def build_prompt(page_content, robot_name):
    """æ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„Promptï¼ŒæŒ‡å¯¼Geminiå®Œæˆä»»åŠ¡"""
    
    desired_json_structure = """
    {
      "name": "Robot's full name",
      "manufacturer": "The company that created the robot",
      "type": "Type of robot (e.g., Quadruped, Humanoid)",
      "specs": {
        "Weight": "Weight of the robot (e.g., 75 kg)",
        "Payload": "Payload capacity (e.g., 25 kg)",
        "Speed": "Maximum speed (e.g., 1.5 m/s)"
      },
      "modules": {
        "Perception": { "components": ["List of sensors like Cameras, LiDAR, IMU"], "suppliers": ["List of potential suppliers"] },
        "Locomotion": { "components": ["List of components like Actuators, Hydraulic systems"], "suppliers": ["List of potential suppliers"] }
      }
    }
    """

    prompt = f"""
    Analyze the text from a webpage about the robot named '{robot_name}'.
    Your task is to extract key information and provide the output ONLY in a valid JSON format.
    The JSON object must strictly adhere to the structure shown below.
    If a piece of information is not available in the text, use "N/A" as the value.
    Do not include any introductory text, closing remarks, or markdown formatting like ```json.
    
    ### Desired JSON Structure:
    {desired_json_structure}

    ### Page Content to Analyze:
    ---
    {page_content[:20000]} 
    ---

    ### Extracted JSON Data:
    """
    return prompt

# --- 3. Serverless Function ä¸»å¤„ç†é€»è¾‘ ---
# Vercelä¼šè‡ªåŠ¨æ‰¾åˆ°è¿™ä¸ªhandlerç±»å¹¶æ‰§è¡Œå®ƒ
class handler(BaseHTTPRequestHandler):
    def do_GET(self):
        # æ£€æŸ¥API Keyæ˜¯å¦å·²é…ç½®ï¼Œè¿™æ˜¯ç¬¬ä¸€é“é˜²çº¿
        if not API_KEY:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Server configuration error: The Gemini API Key is not set."}).encode())
            return

        # è§£æURLï¼Œè·å–ç”¨æˆ·è¾“å…¥çš„æœºå™¨äººåç§°
        query_components = parse_qs(urlparse(self.path).query)
        robot_name = query_components.get('robot', [None])[0]

        if not robot_name:
            self.send_response(400)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Please provide a robot name in the 'robot' parameter."}).encode())
            return
        
        try:
            # æ­¥éª¤A: æ™ºèƒ½æœç´¢ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„ç½‘é¡µ
            print(f"ğŸ•µï¸ Searching for '{robot_name}'...")
            search_query = f"{robot_name} robot wikipedia"
            with DDGS() as ddgs:
                results = list(ddgs.text(search_query, max_results=1))
            
            if not results:
                raise ValueError(f"Could not find any relevant page for '{robot_name}'. Try a more specific name.")
            
            target_url = results[0]['href']
            print(f"ğŸ¯ Found URL: {target_url}")

            # æ­¥éª¤B: è·å–ç½‘é¡µå†…å®¹
            page_response = requests.get(target_url, headers={'User-Agent': 'Robot-Genesis-Live-Analyzer/1.1'})
            page_response.raise_for_status()
            soup = BeautifulSoup(page_response.content, 'html.parser')
            main_content = soup.find(id='mw-content-text') or soup.find('body')
            page_text = main_content.get_text(separator=' ', strip=True)

            # æ­¥éª¤C: AIåˆ†æ
            print(f"âœ¨ Analyzing with Gemini...")
            prompt = build_prompt(page_text, robot_name)
            
            # --- å…³é”®ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨æœ€æ–°çš„ã€é€Ÿåº¦ä¼˜åŒ–çš„æ¨¡å‹ ---
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            
            gemini_response = model.generate_content(prompt, safety_settings=safety_settings)
            
            # ç›´æ¥ä»å“åº”ä¸­è§£æçº¯æ–‡æœ¬JSON
            robot_data = json.loads(gemini_response.text)
            
            # æ­¥éª¤D: æˆåŠŸè¿”å›ç»“æœç»™å‰ç«¯
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(robot_data).encode())

        except Exception as e:
            # ç»Ÿä¸€çš„ã€å¥å£®çš„é”™è¯¯å¤„ç†
            print(f"âŒ An error occurred during the process: {e}")
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": f"An internal error occurred: {str(e)}"}).encode())
